# Abstract

Smart devices were evolving very quickly and played a significant role in our daily life. They are designed to be portable and convenient for users, such as Fitbit and Apple watches. Due the limitation of size, it is very difficult to write or type on these smart devices. Thus, voice input was presented as a substitution for text input. However, voice input extremely depends on real world environment and userâ€™s voice recognition such as accent. Additionally, voice input is relatively much slower compared to text input and it has poor privacy protection. Gesture recognition was also introduced as a replacement for text input, however, it faces the same challenges of efficiency and stability as voice input. In this project, we are going to present a human-computer interaction technology that can overcome the challenges of gesture and voice input, which is wearable virtual keyboard on smart devices. Accelerometer and gyroscope sensors from the Arduino Nano 33 BLE Sense board was used to measure and identify the virtual keystroke being pressed by users. This idea brings convenience to users with much more efficiency and privacy. These sensors are integrated on most of the modern smart device which indicates that it could easily be implemented on commercial products.

# Team

* Xiaowen Chen 
* Spencer Czerwinski

# Required Submissions

* [Proposal](https://github.com/xic3111/ecem202a_project/blob/main/docs/proposal.md)
* [Midterm Checkpoint Presentation Slides](https://docs.google.com/presentation/d/113RK7wwxABVpOcvkmK8OpnIsw39r-BDJzvrKRteDj0g/edit?usp=sharing)
* [Final Presentation Slides](https://docs.google.com/presentation/d/1e60ujslQC1L0h40uCrfIFasl6U8KDsrB8mihsnIh8zI/edit?usp=sharing)
* [Final Report](https://github.com/xic3111/ecem202a_project/blob/main/docs/report.md)
* [Final Presentation](https://youtu.be/2F3fEqxm-Tg)
